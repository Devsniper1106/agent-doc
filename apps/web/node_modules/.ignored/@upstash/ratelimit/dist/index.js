"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  Analytics: () => Analytics,
  MultiRegionRatelimit: () => MultiRegionRatelimit,
  Ratelimit: () => RegionRatelimit
});
module.exports = __toCommonJS(src_exports);

// src/analytics.ts
var import_core_analytics = require("@upstash/core-analytics");
var Analytics = class {
  analytics;
  table = "events";
  constructor(config) {
    this.analytics = new import_core_analytics.Analytics({
      // @ts-expect-error we need to fix the types in core-analytics, it should only require the methods it needs, not the whole sdk
      redis: config.redis,
      window: "1h",
      prefix: config.prefix ?? "@upstash/ratelimit",
      retention: "90d"
    });
  }
  /**
   * Try to extract the geo information from the request
   *
   * This handles Vercel's `req.geo` and  and Cloudflare's `request.cf` properties
   * @param req
   * @returns
   */
  extractGeo(req) {
    if (typeof req.geo !== "undefined") {
      return req.geo;
    }
    if (typeof req.cf !== "undefined") {
      return req.cf;
    }
    return {};
  }
  async record(event) {
    await this.analytics.ingest(this.table, event);
  }
  async series(filter, cutoff) {
    const records = await this.analytics.query(this.table, {
      filter: [filter],
      range: [cutoff, Date.now()]
    });
    return records;
  }
  async getUsage(cutoff = 0) {
    const records = await this.analytics.aggregateBy(this.table, "identifier", {
      range: [cutoff, Date.now()]
    });
    const usage = {};
    for (const bucket of records) {
      for (const [k, v] of Object.entries(bucket)) {
        if (k === "time") {
          continue;
        }
        if (!usage[k]) {
          usage[k] = { success: 0, blocked: 0 };
        }
        usage[k].success += v["true"] ?? 0;
        usage[k].blocked += v["false"] ?? 0;
      }
    }
    return usage;
  }
};

// src/cache.ts
var Cache = class {
  /**
   * Stores identifier -> reset (in milliseconds)
   */
  cache;
  constructor(cache) {
    this.cache = cache;
  }
  isBlocked(identifier) {
    if (!this.cache.has(identifier)) {
      return { blocked: false, reset: 0 };
    }
    const reset = this.cache.get(identifier);
    if (reset < Date.now()) {
      this.cache.delete(identifier);
      return { blocked: false, reset: 0 };
    }
    return { blocked: true, reset };
  }
  blockUntil(identifier, reset) {
    this.cache.set(identifier, reset);
  }
  set(key, value) {
    this.cache.set(key, value);
  }
  get(key) {
    return this.cache.get(key) || null;
  }
  incr(key) {
    let value = this.cache.get(key) ?? 0;
    value += 1;
    this.cache.set(key, value);
    return value;
  }
};

// src/duration.ts
function ms(d) {
  const match = d.match(/^(\d+)\s?(ms|s|m|h|d)$/);
  if (!match) {
    throw new Error(`Unable to parse window size: ${d}`);
  }
  const time = parseInt(match[1]);
  const unit = match[2];
  switch (unit) {
    case "ms":
      return time;
    case "s":
      return time * 1e3;
    case "m":
      return time * 1e3 * 60;
    case "h":
      return time * 1e3 * 60 * 60;
    case "d":
      return time * 1e3 * 60 * 60 * 24;
    default:
      throw new Error(`Unable to parse window size: ${d}`);
  }
}

// src/ratelimit.ts
var Ratelimit = class {
  limiter;
  ctx;
  prefix;
  timeout;
  analytics;
  constructor(config) {
    this.ctx = config.ctx;
    this.limiter = config.limiter;
    this.timeout = config.timeout ?? 5e3;
    this.prefix = config.prefix ?? "@upstash/ratelimit";
    this.analytics = config.analytics ? new Analytics({
      redis: Array.isArray(this.ctx.redis) ? this.ctx.redis[0] : this.ctx.redis,
      prefix: this.prefix
    }) : void 0;
    if (config.ephemeralCache instanceof Map) {
      this.ctx.cache = new Cache(config.ephemeralCache);
    } else if (typeof config.ephemeralCache === "undefined") {
      this.ctx.cache = new Cache(/* @__PURE__ */ new Map());
    }
  }
  /**
   * Determine if a request should pass or be rejected based on the identifier and previously chosen ratelimit.
   *
   * Use this if you want to reject all requests that you can not handle right now.
   *
   * @example
   * ```ts
   *  const ratelimit = new Ratelimit({
   *    redis: Redis.fromEnv(),
   *    limiter: Ratelimit.slidingWindow(10, "10 s")
   *  })
   *
   *  const { success } = await ratelimit.limit(id)
   *  if (!success){
   *    return "Nope"
   *  }
   *  return "Yes"
   * ```
   */
  limit = async (identifier, req) => {
    const key = [this.prefix, identifier].join(":");
    let timeoutId = null;
    try {
      const arr = [this.limiter(this.ctx, key)];
      if (this.timeout > 0) {
        arr.push(
          new Promise((resolve) => {
            timeoutId = setTimeout(() => {
              resolve({
                success: true,
                limit: 0,
                remaining: 0,
                reset: 0,
                pending: Promise.resolve()
              });
            }, this.timeout);
          })
        );
      }
      const res = await Promise.race(arr);
      if (this.analytics) {
        try {
          const geo = req ? this.analytics.extractGeo(req) : void 0;
          const analyticsP = this.analytics.record({
            identifier,
            time: Date.now(),
            success: res.success,
            ...geo
          }).catch((err) => {
            console.warn("Failed to record analytics", err);
          });
          res.pending = Promise.all([res.pending, analyticsP]);
        } catch (err) {
          console.warn("Failed to record analytics", err);
        }
      }
      return res;
    } finally {
      if (timeoutId) {
        clearTimeout(timeoutId);
      }
    }
  };
  /**
   * Block until the request may pass or timeout is reached.
   *
   * This method returns a promise that resolves as soon as the request may be processed
   * or after the timeoue has been reached.
   *
   * Use this if you want to delay the request until it is ready to get processed.
   *
   * @example
   * ```ts
   *  const ratelimit = new Ratelimit({
   *    redis: Redis.fromEnv(),
   *    limiter: Ratelimit.slidingWindow(10, "10 s")
   *  })
   *
   *  const { success } = await ratelimit.blockUntilReady(id, 60_000)
   *  if (!success){
   *    return "Nope"
   *  }
   *  return "Yes"
   * ```
   */
  blockUntilReady = async (identifier, timeout) => {
    if (timeout <= 0) {
      throw new Error("timeout must be positive");
    }
    let res;
    const deadline = Date.now() + timeout;
    while (true) {
      res = await this.limit(identifier);
      if (res.success) {
        break;
      }
      if (res.reset === 0) {
        throw new Error("This should not happen");
      }
      const wait = Math.min(res.reset, deadline) - Date.now();
      await new Promise((r) => setTimeout(r, wait));
      if (Date.now() > deadline) {
        break;
      }
    }
    return res;
  };
};

// src/multi.ts
function randomId() {
  let result = "";
  const characters = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
  const charactersLength = characters.length;
  for (let i = 0; i < 16; i++) {
    result += characters.charAt(Math.floor(Math.random() * charactersLength));
  }
  return result;
}
var MultiRegionRatelimit = class extends Ratelimit {
  /**
   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithn of your choice.
   */
  constructor(config) {
    super({
      prefix: config.prefix,
      limiter: config.limiter,
      timeout: config.timeout,
      analytics: config.analytics,
      ctx: {
        redis: config.redis,
        cache: config.ephemeralCache ? new Cache(config.ephemeralCache) : void 0
      }
    });
  }
  /**
   * Each requests inside a fixed time increases a counter.
   * Once the counter reaches a maxmimum allowed number, all further requests are
   * rejected.
   *
   * **Pro:**
   *
   * - Newer requests are not starved by old ones.
   * - Low storage cost.
   *
   * **Con:**
   *
   * A burst of requests near the boundary of a window can result in a very
   * high request rate because two windows will be filled with requests quickly.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - A fixed timeframe
   */
  static fixedWindow(tokens, window) {
    const windowDuration = ms(window);
    const script = `
    local key     = KEYS[1]
    local id      = ARGV[1]
    local window  = ARGV[2]
    
    redis.call("SADD", key, id)
    local members = redis.call("SMEMBERS", key)
    if #members == 1 then
    -- The first time this key is set, the value will be 1.
    -- So we only need the expire command once
      redis.call("PEXPIRE", key, window)
    end
    
    return members
`;
    return async function(ctx, identifier) {
      if (ctx.cache) {
        const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
        if (blocked) {
          return {
            success: false,
            limit: tokens,
            remaining: 0,
            reset: reset2,
            pending: Promise.resolve()
          };
        }
      }
      const requestID = randomId();
      const bucket = Math.floor(Date.now() / windowDuration);
      const key = [identifier, bucket].join(":");
      const dbs = ctx.redis.map((redis) => ({
        redis,
        request: redis.eval(script, [key], [requestID, windowDuration])
      }));
      const firstResponse = await Promise.any(dbs.map((s) => s.request));
      const usedTokens = firstResponse.length;
      const remaining = tokens - usedTokens - 1;
      async function sync() {
        const individualIDs = await Promise.all(dbs.map((s) => s.request));
        const allIDs = Array.from(new Set(individualIDs.flatMap((_) => _)).values());
        for (const db of dbs) {
          const ids = await db.request;
          if (ids.length >= tokens) {
            continue;
          }
          const diff = allIDs.filter((id) => !ids.includes(id));
          if (diff.length === 0) {
            continue;
          }
          await db.redis.sadd(key, ...allIDs);
        }
      }
      const success = remaining > 0;
      const reset = (bucket + 1) * windowDuration;
      if (ctx.cache && !success) {
        ctx.cache.blockUntil(identifier, reset);
      }
      return {
        success,
        limit: tokens,
        remaining,
        reset,
        pending: sync()
      };
    };
  }
  /**
   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage
   * costs than `slidingLogs` and improved boundary behavior by calcualting a
   * weighted score between two windows.
   *
   * **Pro:**
   *
   * Good performance allows this to scale to very high loads.
   *
   * **Con:**
   *
   * Nothing major.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - The duration in which the user can max X requests.
   */
  static slidingWindow(tokens, window) {
    const windowSize = ms(window);
    const script = `
      local currentKey  = KEYS[1]           -- identifier including prefixes
      local previousKey = KEYS[2]           -- key of the previous bucket
      local tokens      = tonumber(ARGV[1]) -- tokens per window
      local now         = ARGV[2]           -- current timestamp in milliseconds
      local window      = ARGV[3]           -- interval in milliseconds
      local requestID   = ARGV[4]           -- uuid for this request


      local currentMembers = redis.call("SMEMBERS", currentKey)
      local requestsInCurrentWindow = #currentMembers
      local previousMembers = redis.call("SMEMBERS", previousKey)
      local requestsInPreviousWindow = #previousMembers

      local percentageInCurrent = ( now % window) / window
      if requestsInPreviousWindow * ( 1 - percentageInCurrent ) + requestsInCurrentWindow >= tokens then
        return {currentMembers, previousMembers}
      end

      redis.call("SADD", currentKey, requestID)
      table.insert(currentMembers, requestID)
      if requestsInCurrentWindow == 0 then 
        -- The first time this key is set, the value will be 1.
        -- So we only need the expire command once
        redis.call("PEXPIRE", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second
      end
      return {currentMembers, previousMembers}
      `;
    const windowDuration = ms(window);
    return async function(ctx, identifier) {
      if (ctx.cache) {
        const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
        if (blocked) {
          return {
            success: false,
            limit: tokens,
            remaining: 0,
            reset: reset2,
            pending: Promise.resolve()
          };
        }
      }
      const requestID = randomId();
      const now = Date.now();
      const currentWindow = Math.floor(now / windowSize);
      const currentKey = [identifier, currentWindow].join(":");
      const previousWindow = currentWindow - windowSize;
      const previousKey = [identifier, previousWindow].join(":");
      const dbs = ctx.redis.map((redis) => ({
        redis,
        request: redis.eval(script, [currentKey, previousKey], [tokens, now, windowDuration, requestID])
      }));
      const percentageInCurrent = now % windowDuration / windowDuration;
      const [current, previous] = await Promise.any(dbs.map((s) => s.request));
      const usedTokens = previous.length * (1 - percentageInCurrent) + current.length;
      const remaining = tokens - usedTokens;
      async function sync() {
        const [individualIDs] = await Promise.all(dbs.map((s) => s.request));
        const allIDs = Array.from(new Set(individualIDs.flatMap((_) => _)).values());
        for (const db of dbs) {
          const [ids] = await db.request;
          if (ids.length >= tokens) {
            continue;
          }
          const diff = allIDs.filter((id) => !ids.includes(id));
          if (diff.length === 0) {
            continue;
          }
          await db.redis.sadd(currentKey, ...allIDs);
        }
      }
      const success = remaining > 0;
      const reset = (currentWindow + 1) * windowDuration;
      if (ctx.cache && !success) {
        ctx.cache.blockUntil(identifier, reset);
      }
      return {
        success,
        limit: tokens,
        remaining,
        reset,
        pending: sync()
      };
    };
  }
};

// src/single.ts
var RegionRatelimit = class extends Ratelimit {
  /**
   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithn of your choice.
   */
  constructor(config) {
    super({
      prefix: config.prefix,
      limiter: config.limiter,
      timeout: config.timeout,
      analytics: config.analytics,
      ctx: {
        redis: config.redis
      },
      ephemeralCache: config.ephemeralCache
    });
  }
  /**
   * Each requests inside a fixed time increases a counter.
   * Once the counter reaches a maxmimum allowed number, all further requests are
   * rejected.
   *
   * **Pro:**
   *
   * - Newer requests are not starved by old ones.
   * - Low storage cost.
   *
   * **Con:**
   *
   * A burst of requests near the boundary of a window can result in a very
   * high request rate because two windows will be filled with requests quickly.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - A fixed timeframe
   */
  static fixedWindow(tokens, window) {
    const windowDuration = ms(window);
    const script = `
    local key     = KEYS[1]
    local window  = ARGV[1]
    
    local r = redis.call("INCR", key)
    if r == 1 then 
    -- The first time this key is set, the value will be 1.
    -- So we only need the expire command once
    redis.call("PEXPIRE", key, window)
    end
    
    return r
    `;
    return async function(ctx, identifier) {
      const bucket = Math.floor(Date.now() / windowDuration);
      const key = [identifier, bucket].join(":");
      if (ctx.cache) {
        const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
        if (blocked) {
          return {
            success: false,
            limit: tokens,
            remaining: 0,
            reset: reset2,
            pending: Promise.resolve()
          };
        }
      }
      const usedTokensAfterUpdate = await ctx.redis.eval(script, [key], [windowDuration]);
      const success = usedTokensAfterUpdate <= tokens;
      const reset = (bucket + 1) * windowDuration;
      if (ctx.cache && !success) {
        ctx.cache.blockUntil(identifier, reset);
      }
      return {
        success,
        limit: tokens,
        remaining: tokens - usedTokensAfterUpdate,
        reset,
        pending: Promise.resolve()
      };
    };
  }
  /**
   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage
   * costs than `slidingLogs` and improved boundary behavior by calcualting a
   * weighted score between two windows.
   *
   * **Pro:**
   *
   * Good performance allows this to scale to very high loads.
   *
   * **Con:**
   *
   * Nothing major.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - The duration in which the user can max X requests.
   */
  static slidingWindow(tokens, window) {
    const script = `
      local currentKey  = KEYS[1]           -- identifier including prefixes
      local previousKey = KEYS[2]           -- key of the previous bucket
      local tokens      = tonumber(ARGV[1]) -- tokens per window
      local now         = ARGV[2]           -- current timestamp in milliseconds
      local window      = ARGV[3]           -- interval in milliseconds

      local requestsInCurrentWindow = redis.call("GET", currentKey)
      if requestsInCurrentWindow == false then
        requestsInCurrentWindow = -1
      end


      local requestsInPreviousWindow = redis.call("GET", previousKey)
      if requestsInPreviousWindow == false then
        requestsInPreviousWindow = 0
      end
      local percentageInCurrent = ( now % window) / window
      if requestsInPreviousWindow * ( 1 - percentageInCurrent ) + requestsInCurrentWindow >= tokens then
        return -1
      end

      local newValue = redis.call("INCR", currentKey)
      if newValue == 1 then 
        -- The first time this key is set, the value will be 1.
        -- So we only need the expire command once
        redis.call("PEXPIRE", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second
      end
      return tokens - newValue
      `;
    const windowSize = ms(window);
    return async function(ctx, identifier) {
      const now = Date.now();
      const currentWindow = Math.floor(now / windowSize);
      const currentKey = [identifier, currentWindow].join(":");
      const previousWindow = currentWindow - windowSize;
      const previousKey = [identifier, previousWindow].join(":");
      if (ctx.cache) {
        const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
        if (blocked) {
          return {
            success: false,
            limit: tokens,
            remaining: 0,
            reset: reset2,
            pending: Promise.resolve()
          };
        }
      }
      const remaining = await ctx.redis.eval(script, [currentKey, previousKey], [tokens, now, windowSize]);
      const success = remaining >= 0;
      const reset = (currentWindow + 1) * windowSize;
      if (ctx.cache && !success) {
        ctx.cache.blockUntil(identifier, reset);
      }
      return {
        success,
        limit: tokens,
        remaining: Math.max(0, remaining),
        reset,
        pending: Promise.resolve()
      };
    };
  }
  /**
   * You have a bucket filled with `{maxTokens}` tokens that refills constantly
   * at `{refillRate}` per `{interval}`.
   * Every request will remove one token from the bucket and if there is no
   * token to take, the request is rejected.
   *
   * **Pro:**
   *
   * - Bursts of requests are smoothed out and you can process them at a constant
   * rate.
   * - Allows to set a higher initial burst limit by setting `maxTokens` higher
   * than `refillRate`
   */
  static tokenBucket(refillRate, interval, maxTokens) {
    const script = `
        local key         = KEYS[1]           -- identifier including prefixes
        local maxTokens   = tonumber(ARGV[1]) -- maximum number of tokens
        local interval    = tonumber(ARGV[2]) -- size of the window in milliseconds
        local refillRate  = tonumber(ARGV[3]) -- how many tokens are refilled after each interval
        local now         = tonumber(ARGV[4]) -- current timestamp in milliseconds
        local remaining   = 0
        
        local bucket = redis.call("HMGET", key, "updatedAt", "tokens")
        
        if bucket[1] == false then
          -- The bucket does not exist yet, so we create it and add a ttl.
          remaining = maxTokens - 1
          
          redis.call("HMSET", key, "updatedAt", now, "tokens", remaining)
          redis.call("PEXPIRE", key, interval)
  
          return {remaining, now + interval}
        end

        -- The bucket does exist
  
        local updatedAt = tonumber(bucket[1])
        local tokens = tonumber(bucket[2])
  
        if now >= updatedAt + interval then
          remaining = math.min(maxTokens, tokens + refillRate) - 1
          
          redis.call("HMSET", key, "updatedAt", now, "tokens", remaining)
          return {remaining, now + interval}
        end
  
        if tokens > 0 then
          remaining = tokens - 1
          redis.call("HMSET", key, "updatedAt", now, "tokens", remaining)
        end
  
        return {remaining, updatedAt + interval}
       `;
    const intervalDuration = ms(interval);
    return async function(ctx, identifier) {
      if (ctx.cache) {
        const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
        if (blocked) {
          return {
            success: false,
            limit: maxTokens,
            remaining: 0,
            reset: reset2,
            pending: Promise.resolve()
          };
        }
      }
      const now = Date.now();
      const key = [identifier, Math.floor(now / intervalDuration)].join(":");
      const [remaining, reset] = await ctx.redis.eval(
        script,
        [key],
        [maxTokens, intervalDuration, refillRate, now]
      );
      const success = remaining > 0;
      if (ctx.cache && !success) {
        ctx.cache.blockUntil(identifier, reset);
      }
      return {
        success,
        limit: maxTokens,
        remaining,
        reset,
        pending: Promise.resolve()
      };
    };
  }
  /**
   * cachedFixedWindow first uses the local cache to decide if a request may pass and then updates
   * it asynchronously.
   * This is experimental and not yet recommended for production use.
   *
   * @experimental
   *
   * Each requests inside a fixed time increases a counter.
   * Once the counter reaches a maxmimum allowed number, all further requests are
   * rejected.
   *
   * **Pro:**
   *
   * - Newer requests are not starved by old ones.
   * - Low storage cost.
   *
   * **Con:**
   *
   * A burst of requests near the boundary of a window can result in a very
   * high request rate because two windows will be filled with requests quickly.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - A fixed timeframe
   */
  static cachedFixedWindow(tokens, window) {
    const windowDuration = ms(window);
    const script = `
      local key     = KEYS[1]
      local window  = ARGV[1]
      
      local r = redis.call("INCR", key)
      if r == 1 then 
      -- The first time this key is set, the value will be 1.
      -- So we only need the expire command once
      redis.call("PEXPIRE", key, window)
      end
      
      return r
      `;
    return async function(ctx, identifier) {
      if (!ctx.cache) {
        throw new Error("This algorithm requires a cache");
      }
      const bucket = Math.floor(Date.now() / windowDuration);
      const key = [identifier, bucket].join(":");
      const reset = (bucket + 1) * windowDuration;
      const hit = typeof ctx.cache.get(key) === "number";
      if (hit) {
        const cachedTokensAfterUpdate = ctx.cache.incr(key);
        const success = cachedTokensAfterUpdate < tokens;
        const pending = success ? ctx.redis.eval(script, [key], [windowDuration]).then((t) => {
          ctx.cache.set(key, t);
        }) : Promise.resolve();
        return {
          success,
          limit: tokens,
          remaining: tokens - cachedTokensAfterUpdate,
          reset,
          pending
        };
      }
      const usedTokensAfterUpdate = await ctx.redis.eval(script, [key], [windowDuration]);
      ctx.cache.set(key, usedTokensAfterUpdate);
      const remaining = tokens - usedTokensAfterUpdate;
      return {
        success: remaining >= 0,
        limit: tokens,
        remaining,
        reset,
        pending: Promise.resolve()
      };
    };
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  Analytics,
  MultiRegionRatelimit,
  Ratelimit
});
//# sourceMappingURL=index.js.map